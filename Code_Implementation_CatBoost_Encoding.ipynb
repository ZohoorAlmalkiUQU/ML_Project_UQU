{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02554b9a-4a5d-4ca0-8b12-076f45afa0ea",
   "metadata": {},
   "source": [
    "# Antibiotic resistance prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782d8e5d-14df-428e-827c-c330da186a7d",
   "metadata": {},
   "source": [
    "## Project Introduction\n",
    "This project aims to predict antibiotic resistance using structured electronic health record (EHR) data from the Antibiotic Resistance Microbiology Dataset (ARMD). The goal is to classify whether a bacterial isolate is susceptible (S) or resistant (R) to a given antibiotic, based on clinical, demographic, microbiological, and treatment-related features. This binary classification model supports empirical antibiotic selection and contributes to combating antimicrobial resistance in clinical settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "947f277e-8d3e-44aa-bc37-e1daae2cca87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2184195, 27)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "final_armd_ds = 'ARMD_Dataset/selected_features_output.parquet'\n",
    "\n",
    "df = pd.read_parquet(final_armd_ds)\n",
    "print(df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da80262e-189b-4caf-98ad-2d023a78a4e2",
   "metadata": {},
   "source": [
    "### Separate target + binary encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08762e35-c894-477c-a046-1a62d0691e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:  (2184195,)\n",
      "X:  (2184195, 26)\n"
     ]
    }
   ],
   "source": [
    "target_col = 'susceptibility_label'\n",
    "df[target_col] = df[target_col].map({'S': 0, 'R': 1})  \n",
    "y = df[target_col]\n",
    "X = df.drop(columns=[target_col])\n",
    "print('y: ',y.shape)\n",
    "print('X: ',X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd23cb24-2e0e-4876-b66c-0ff9c5eaddec",
   "metadata": {},
   "source": [
    "### Identify column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9076309f-91ae-4b19-9545-cdcab95eadeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2184195 entries, 0 to 2184194\n",
      "Data columns (total 26 columns):\n",
      " #   Column                          Dtype  \n",
      "---  ------                          -----  \n",
      " 0   organism_x                      string \n",
      " 1   antibiotic_x                    string \n",
      " 2   resistant_time_to_culturetime   float64\n",
      " 3   age                             string \n",
      " 4   gender                          string \n",
      " 5   adi_score                       string \n",
      " 6   adi_state_rank                  string \n",
      " 7   median_wbc                      string \n",
      " 8   median_neutrophils              string \n",
      " 9   median_lymphocytes              string \n",
      " 10  median_hgb                      string \n",
      " 11  median_plt                      string \n",
      " 12  median_na                       string \n",
      " 13  median_hco3                     string \n",
      " 14  median_bun                      string \n",
      " 15  median_cr                       string \n",
      " 16  median_lactate                  string \n",
      " 17  median_procalcitonin            string \n",
      " 18  median_heartrate                float32\n",
      " 19  median_resprate                 float32\n",
      " 20  median_temp                     float32\n",
      " 21  median_sysbp                    float32\n",
      " 22  median_diasbp                   float32\n",
      " 23  medication_category             string \n",
      " 24  medication_time_to_culturetime  float64\n",
      " 25  nursing_home_visit_culture      float64\n",
      "dtypes: float32(5), float64(3), string(18)\n",
      "memory usage: 391.6 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fdf721-f1e5-421a-8e5a-48499766fecd",
   "metadata": {},
   "source": [
    "## Column Categorization\n",
    "- First, properly define all column categories\n",
    "- Combine numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2e6693d-0761-4f4a-b7b5-bfe2a0ee4b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_categorical_cols = ['organism_x', 'antibiotic_x', 'gender', 'medication_category']\n",
    "numeric_cols = ['resistant_time_to_culturetime', 'median_heartrate', 'median_resprate',\n",
    "               'median_temp', 'median_sysbp', 'median_diasbp',\n",
    "               'medication_time_to_culturetime', 'nursing_home_visit_culture']\n",
    "numerical_med_cols = ['median_wbc', 'median_neutrophils', 'median_lymphocytes',\n",
    "                     'median_hgb', 'median_plt', 'median_na', 'median_hco3',\n",
    "                     'median_bun', 'median_cr', 'median_lactate', 'median_procalcitonin']\n",
    "ordinal_cols = ['age', 'adi_score', 'adi_state_rank']\n",
    "\n",
    "\n",
    "all_numerical_cols = numeric_cols + numerical_med_cols\n",
    "\n",
    "\n",
    "all_columns = true_categorical_cols + all_numerical_cols + ordinal_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0b7f7e-f59a-4859-9727-02de59399bbc",
   "metadata": {},
   "source": [
    "## Apply CatBoost Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5692c4ab-7b57-4187-ab8b-e2f6a5f3f1c2",
   "metadata": {},
   "source": [
    "#### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "475b0d3b-4f5c-44ea-bfb4-1c995f3797c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Training Set Shape: (1747356, 26)\n",
      "Final Test Set Shape: (436839, 26)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\nFinal Training Set Shape:\", X_train.shape)\n",
    "print(\"Final Test Set Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cbda01-8784-475b-89bf-f0e2bf286b47",
   "metadata": {},
   "source": [
    "#### Ensure proper data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55607105-6a27-49ce-9176-a75d6d7cde80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[true_categorical_cols] = X_train[true_categorical_cols].astype(str)\n",
    "X_test[true_categorical_cols] = X_test[true_categorical_cols].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ff693b-b34b-459c-a5fc-cfad694dd585",
   "metadata": {},
   "source": [
    "#### Handle missing \n",
    "- Replace 'Null' with actual NaN values\n",
    "- **For numerical columns**: Simple imputation (fill with mean/median/mode)\n",
    "- **For categorical columns (if any)**: Fill with the most frequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92506bb1-c1d6-4096-adb9-75e1986816b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after conversion:\n",
      "resistant_time_to_culturetime       23366\n",
      "median_heartrate                    23822\n",
      "median_resprate                     27518\n",
      "median_temp                         24637\n",
      "median_sysbp                        24087\n",
      "median_diasbp                       24087\n",
      "medication_time_to_culturetime      29372\n",
      "nursing_home_visit_culture        1746678\n",
      "median_wbc                          14553\n",
      "median_neutrophils                 149408\n",
      "median_lymphocytes                 148739\n",
      "median_hgb                          14553\n",
      "median_plt                          14553\n",
      "median_na                            9819\n",
      "median_hco3                          9832\n",
      "median_bun                           9862\n",
      "median_cr                            9805\n",
      "median_lactate                      88682\n",
      "median_procalcitonin               149347\n",
      "dtype: int64\n",
      "\n",
      "Missing values after imputation:\n",
      "resistant_time_to_culturetime     0\n",
      "median_heartrate                  0\n",
      "median_resprate                   0\n",
      "median_temp                       0\n",
      "median_sysbp                      0\n",
      "median_diasbp                     0\n",
      "medication_time_to_culturetime    0\n",
      "nursing_home_visit_culture        0\n",
      "median_wbc                        0\n",
      "median_neutrophils                0\n",
      "median_lymphocytes                0\n",
      "median_hgb                        0\n",
      "median_plt                        0\n",
      "median_na                         0\n",
      "median_hco3                       0\n",
      "median_bun                        0\n",
      "median_cr                         0\n",
      "median_lactate                    0\n",
      "median_procalcitonin              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def safe_impute(train_df, test_df, num_cols):\n",
    "    \"\"\"\n",
    "    Safely impute missing values in numerical columns, handling persistent NA types\n",
    "    \"\"\"\n",
    "    # 1. Make copies to avoid SettingWithCopyWarning\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    \n",
    "    # 2. Force convert all numerical columns to float, coercing errors\n",
    "    for col in num_cols:\n",
    "        train_df[col] = pd.to_numeric(train_df[col], errors='coerce')\n",
    "        test_df[col] = pd.to_numeric(test_df[col], errors='coerce')\n",
    "    \n",
    "    # 3. Convert all possible NA representations to np.nan\n",
    "    na_values = [pd.NA, pd.NaT, np.nan, None, 'NA', 'NaN', 'nan', 'null', 'Null']\n",
    "    train_df[num_cols] = train_df[num_cols].replace(na_values, np.nan)\n",
    "    test_df[num_cols] = test_df[num_cols].replace(na_values, np.nan)\n",
    "    \n",
    "    # 4. Verify conversion\n",
    "    print(\"Missing values after conversion:\")\n",
    "    print(train_df[num_cols].isna().sum())\n",
    "    \n",
    "    # 5. Impute using median - convert to numpy arrays first\n",
    "    num_imputer = SimpleImputer(strategy='median')\n",
    "    \n",
    "    # Fit on training data\n",
    "    train_imputed = num_imputer.fit_transform(train_df[num_cols])\n",
    "    test_imputed = num_imputer.transform(test_df[num_cols])\n",
    "    \n",
    "    # Convert back to DataFrame\n",
    "    train_df[num_cols] = pd.DataFrame(train_imputed, \n",
    "                                    columns=num_cols,\n",
    "                                    index=train_df.index)\n",
    "    test_df[num_cols] = pd.DataFrame(test_imputed,\n",
    "                                   columns=num_cols,\n",
    "                                   index=test_df.index)\n",
    "    \n",
    "    # 6. Final verification\n",
    "    print(\"\\nMissing values after imputation:\")\n",
    "    print(train_df[num_cols].isna().sum())\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "# Apply to your data\n",
    "X_train, X_test = safe_impute(X_train, X_test, all_numerical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae773c71-f990-40ed-ae18-e1a2f1649676",
   "metadata": {},
   "source": [
    "####  Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a4881a0-5094-4a91-a7b7-3b326006a45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded value counts:\n",
      "\n",
      "age:\n",
      "age\n",
      "0      92143\n",
      "1      10277\n",
      "2       3094\n",
      "3      69539\n",
      "4    1551797\n",
      "5       9668\n",
      "6       7598\n",
      "7       1524\n",
      "8       1716\n",
      "Name: count, dtype: int64\n",
      "\n",
      "adi_score:\n",
      "adi_score\n",
      "-1    1747356\n",
      "Name: count, dtype: int64\n",
      "\n",
      "adi_state_rank:\n",
      "adi_state_rank\n",
      "-1    1747356\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1. First convert ALL ordinal columns to strings\n",
    "ordinal_cols = ['age', 'adi_score', 'adi_state_rank']\n",
    "X_train_ordinal = X_train[ordinal_cols].astype(str)\n",
    "X_test_ordinal = X_test[ordinal_cols].astype(str)\n",
    "\n",
    "# 2. Define proper ordering (after seeing your value counts)\n",
    "age_order = [\n",
    "    '18-24 years', \n",
    "    '25-34 years',\n",
    "    '35-44 years',\n",
    "    '45-54 years',\n",
    "    '55-64 years',\n",
    "    '65-74 years',\n",
    "    '75-84 years',\n",
    "    '85-89 years',\n",
    "    'above 90'\n",
    "]\n",
    "\n",
    "# For numeric ordinals, convert to float first, then sort\n",
    "adi_order = sorted([float(x) for x in X['adi_score'].unique() if x not in ['Null', 'missing']])\n",
    "rank_order = sorted([float(x) for x in X['adi_state_rank'].unique() if x not in ['Null', 'missing']])\n",
    "\n",
    "# 3. Create the pipeline with proper string handling\n",
    "ordinal_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('encoder', OrdinalEncoder(\n",
    "        categories=[age_order, adi_order, rank_order],\n",
    "        handle_unknown='use_encoded_value',\n",
    "        unknown_value=-1,\n",
    "        dtype=np.int32\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 4. Fit and transform\n",
    "ordinal_pipeline.fit(X_train_ordinal)\n",
    "X_train[ordinal_cols] = ordinal_pipeline.transform(X_train_ordinal)\n",
    "X_test[ordinal_cols] = ordinal_pipeline.transform(X_test_ordinal)\n",
    "\n",
    "# 5. Verification\n",
    "print(\"Encoded value counts:\")\n",
    "for col in ordinal_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(pd.Series(X_train[col]).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d12b1b-aed6-44e0-8717-1a10ddba230b",
   "metadata": {},
   "source": [
    "#### Apply CatBoost Encoding\n",
    "Initialize CatBoost encoder with optimal settings\n",
    "- Added noise to prevent overfitting\n",
    "- Smoothing parameter\n",
    "\n",
    "Fit and transform - ensuring no data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17524eb1-c434-449a-832a-9688d51b4221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import CatBoostEncoder\n",
    "cbe = CatBoostEncoder(\n",
    "    cols=true_categorical_cols,\n",
    "    random_state=42,\n",
    "    sigma=0.1,  # noise\n",
    "    a=1.0       # Smoothing\n",
    ")\n",
    "\n",
    "X_train_encoded = cbe.fit_transform(X_train[true_categorical_cols], y_train)\n",
    "X_test_encoded = cbe.transform(X_test[true_categorical_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea016aa-2ebd-4ea1-8007-66c9fdba5987",
   "metadata": {},
   "source": [
    "#### Create final feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "075d7962-81dd-4020-a733-732ad0a93689",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = true_categorical_cols + all_numerical_cols + ordinal_cols\n",
    "X_train_final = pd.concat([\n",
    "    X_train_encoded,\n",
    "    X_train[all_numerical_cols + ordinal_cols]\n",
    "], axis=1)[final_features]  # Ensure consistent column order\n",
    "\n",
    "X_test_final = pd.concat([\n",
    "    X_test_encoded,\n",
    "    X_test[all_numerical_cols + ordinal_cols]\n",
    "], axis=1)[final_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4467187-a9c5-4327-9d19-a85bfeddb0b0",
   "metadata": {},
   "source": [
    "#### Final verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18c9527b-454f-4555-b6c3-207723c5dcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoded values validation:\n",
      "\n",
      "organism_x:\n",
      "Unique encoded values: 1747356\n",
      "Value distribution:\n",
      "count    1.747356e+06\n",
      "mean     4.278171e-01\n",
      "std      7.143352e-02\n",
      "min      2.213322e-03\n",
      "25%      4.044311e-01\n",
      "50%      4.385614e-01\n",
      "75%      4.702068e-01\n",
      "max      1.070724e+00\n",
      "Name: organism_x, dtype: float64\n",
      "\n",
      "antibiotic_x:\n",
      "Unique encoded values: 1747356\n",
      "Value distribution:\n",
      "count    1.747356e+06\n",
      "mean     4.279686e-01\n",
      "std      1.163655e-01\n",
      "min      6.041039e-03\n",
      "25%      3.878881e-01\n",
      "50%      4.214420e-01\n",
      "75%      4.539043e-01\n",
      "max      1.249172e+00\n",
      "Name: antibiotic_x, dtype: float64\n",
      "\n",
      "gender:\n",
      "Unique encoded values: 1747356\n",
      "Value distribution:\n",
      "count    1.747356e+06\n",
      "mean     4.278894e-01\n",
      "std      4.723353e-02\n",
      "min      1.254375e-01\n",
      "25%      3.959535e-01\n",
      "50%      4.259338e-01\n",
      "75%      4.572970e-01\n",
      "max      7.193763e-01\n",
      "Name: gender, dtype: float64\n",
      "\n",
      "medication_category:\n",
      "Unique encoded values: 1747356\n",
      "Value distribution:\n",
      "count    1.747356e+06\n",
      "mean     4.278501e-01\n",
      "std      7.062163e-02\n",
      "min      2.895311e-02\n",
      "25%      3.932419e-01\n",
      "50%      4.258375e-01\n",
      "75%      4.628545e-01\n",
      "max      9.680906e-01\n",
      "Name: medication_category, dtype: float64\n",
      "\n",
      "Final training set shape: (1747356, 26)\n",
      "Final test set shape: (436839, 26)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEncoded values validation:\")\n",
    "for col in true_categorical_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"Unique encoded values: {X_train_encoded[col].nunique()}\")\n",
    "    print(\"Value distribution:\")\n",
    "    print(X_train_encoded[col].describe())\n",
    "\n",
    "print(\"\\nFinal training set shape:\", X_train_final.shape)\n",
    "print(\"Final test set shape:\", X_test_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23ac851-4199-4da0-a653-220cf0716249",
   "metadata": {},
   "source": [
    "## Models implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f05a06-93d0-4a40-8231-9c5e210210b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler  # Better for outliers\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# 1. More balanced class weighting\n",
    "model = make_pipeline(\n",
    "    RobustScaler(),  # Handles outliers better than StandardScaler\n",
    "    LogisticRegression(\n",
    "        max_iter=5000,\n",
    "        class_weight='balanced',  # Auto-balance (better than manual here)\n",
    "        random_state=42,\n",
    "        solver='saga',\n",
    "        penalty='l2',  # Simpler regularization\n",
    "        C=0.1  # Stronger regularization\n",
    "    )\n",
    ")\n",
    "\n",
    "# 2. Train with calibration\n",
    "calibrated_model = CalibratedClassifierCV(model, cv=3)\n",
    "calibrated_model.fit(X_train_final, y_train)\n",
    "\n",
    "# 3. Adjust prediction threshold\n",
    "y_prob = calibrated_model.predict_proba(X_test_final)[:,1]\n",
    "y_pred_adj = (y_prob > 0.4).astype(int)  # Lower threshold from 0.5 to 0.4\n",
    "\n",
    "# 4. Enhanced evaluation\n",
    "print(\"Balanced Logistic Regression\")\n",
    "print(classification_report(y_test, y_pred_adj))\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_prob):.3f}\")\n",
    "print(\"\\nAdjusted Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_adj))\n",
    "\n",
    "# 5. Visualize probability distributions\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.hist(y_prob[y_test==0], bins=50, alpha=0.5, label='Class 0')\n",
    "plt.hist(y_prob[y_test==1], bins=50, alpha=0.5, label='Class 1')\n",
    "plt.legend()\n",
    "plt.title(\"Predicted Probability Distributions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee38a00-f1cb-4998-8db1-34d7a5724f96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
