{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c3c1edf-4d21-44a5-9df3-75ffeb2e9f56",
   "metadata": {},
   "source": [
    "# Take a sample of ARMD Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2013cd8-a1f5-4388-aecc-b05009553cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "linked_features = ['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded', 'order_time_jittered_utc']\n",
    "\n",
    "files_info = [\n",
    "    {\n",
    "        \"name\": \"cultures_cohort\",\n",
    "        \"path\": \"microbiology_cultures_cohort.csv\",\n",
    "        \"merge_on\": linked_features, \n",
    "        \"dtype\": {\n",
    "            \"ordering_mode\": \"object\",\n",
    "            \"culture_description\": \"object\",\n",
    "            \"was_positive\": \"Int64\",\n",
    "            \"organism\": \"object\",\n",
    "            \"antibiotic\": \"object\",\n",
    "            \"susceptibility\": \"object\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ward_info\",\n",
    "        \"path\": \"microbiology_cultures_ward_info.csv\",\n",
    "        \"merge_on\": linked_features, \n",
    "        \"dtype\": {\n",
    "            \"hosp_ward_IP\": \"Int64\",\n",
    "            \"hosp_ward_OP\": \"Int64\",\n",
    "            \"hosp_ward_ER\": \"Int64\",\n",
    "            \"hosp_ward_ICU\": \"Int64\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"prior_med\",\n",
    "        \"path\": \"microbiology_cultures_prior_med.csv\",\n",
    "        \"merge_on\": linked_features,\n",
    "        \"dtype\": {\n",
    "            \"medication_name\": \"object\",\n",
    "            \"medication_time_to_culturetime\": \"Int64\",\n",
    "            \"medication_category\": \"object\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"microbial_resistance\",\n",
    "        \"path\": \"microbiology_cultures_microbial_resistance.csv\",\n",
    "        \"merge_on\": linked_features, \n",
    "        \"dtype\": {\n",
    "            \"organism\": \"object\",\n",
    "            \"antibiotic\": \"object\",\n",
    "            \"resistant_time_to_culturetime\": \"Int64\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"cultures_demographics\",\n",
    "        \"path\": \"microbiology_cultures_demographics.csv\",\n",
    "        \"merge_on\": linked_features[:3], \n",
    "        \"dtype\": {\n",
    "            \"age\": \"object\",\n",
    "            \"gender\": \"object\"\n",
    "        }\n",
    "    },\n",
    "     {\n",
    "        \"name\": \"cultures_labs\",\n",
    "        \"path\": \"microbiology_cultures_labs.csv\",\n",
    "        \"merge_on\": linked_features[:3], \n",
    "        \"dtype\": {\n",
    "            \"Period_Day\": \"Int64\",\n",
    "            \"Q75_wbc\": \"object\",\n",
    "            \"Q25_wbc\": \"object\",\n",
    "            \"median_wbc\": \"object\",\n",
    "            \"Q25_neutrophils\": \"float64\",\n",
    "            \"Q75_neutrophils\": \"float64\",\n",
    "            \"median_neutrophils\": \"float64\",\n",
    "            \"Q25_lymphocytes\": \"float64\",\n",
    "            \"Q75_lymphocytes\": \"float64\",\n",
    "            \"median_lymphocytes\": \"float64\",\n",
    "            \"Q25_hgb\": \"object\",\n",
    "            \"Q75_hgb\": \"object\",\n",
    "            \"median_hgb\": \"object\",\n",
    "            \"Q25_plt\": \"object\",\n",
    "            \"Q75_plt\": \"object\",\n",
    "            \"median_plt\": \"object\",\n",
    "            \"Q75_na\": \"object\",\n",
    "            \"Q25_na\": \"object\",\n",
    "            \"median_na\": \"object\",\n",
    "            \"Q75_hco3\": \"object\",\n",
    "            \"Q25_hco3\": \"object\",\n",
    "            \"median_hco3\": \"object\",\n",
    "            \"Q75_bun\": \"object\",\n",
    "            \"Q25_bun\": \"object\",\n",
    "            \"median_bun\": \"object\",\n",
    "            \"Q75_cr\": \"object\",\n",
    "            \"Q25_cr\": \"object\",\n",
    "            \"median_cr\": \"object\",\n",
    "            \"Q75_lactate\": \"object\",\n",
    "            \"Q25_lactate\": \"object\",\n",
    "            \"median_lactate\": \"object\",\n",
    "            \"Q75_procalcitonin\": \"object\",\n",
    "            \"Q25_procalcitonin\": \"object\",\n",
    "            \"median_procalcitonin\": \"object\",\n",
    "            \"first_procalcitonin\": \"object\",\n",
    "            \"last_procalcitonin\": \"object\",\n",
    "            \"first_lactate\":\"object\",\n",
    "            \"last_cr\":\"object\",\n",
    "            \"first_cr\":\"object\",\n",
    "            \"last_bun\":\"object\",\n",
    "            \"first_bun\":\"object\",\n",
    "            \"last_hco3\":\"object\",\n",
    "            \"first_hco3\":\"object\",\n",
    "            \"last_na\":\"object\",\n",
    "            \"first_na\":\"object\",\n",
    "            \"last_plt\":\"object\",\n",
    "            \"first_plt\":\"object\",\n",
    "            \"last_hgb\":\"object\",\n",
    "            \"first_hgb\":\"object\",\n",
    "            \"last_lymphocytes\":\"object\",\n",
    "            \"first_lymphocytes\":\"object\",\n",
    "            \"last_neutrophils\":\"object\",\n",
    "            \"first_neutrophils\":\"object\",\n",
    "            \"last_wbc\":\"object\",\n",
    "            \"first_wbc\":\"object\" \n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"cultures_vitals\",\n",
    "        \"path\": \"microbiology_cultures_vitals.csv\",\n",
    "        \"merge_on\": linked_features[:3],\n",
    "        \"dtype\": {\n",
    "            \"Q25_heartrate\": \"object\",\n",
    "            \"Q75_heartrate\": \"object\",\n",
    "            \"median_heartrate\": \"object\",\n",
    "            \"Q25_resprate\": \"object\",\n",
    "            \"Q75_resprate\": \"object\",\n",
    "            \"median_resprate\": \"object\",\n",
    "            \"Q25_temp\": \"object\",\n",
    "            \"Q75_temp\": \"object\",\n",
    "            \"median_temp\": \"object\",\n",
    "            \"Q25_sysbp\": \"float64\",\n",
    "            \"Q75_sysbp\": \"float64\",\n",
    "            \"median_sysbp\": \"float64\",\n",
    "            \"Q25_diasbp\": \"float64\",\n",
    "            \"Q75_diasbp\": \"float64\",\n",
    "            \"median_diasbp\": \"float64\",\n",
    "            \"first_diasbp\": \"object\",\n",
    "            \"last_diasbp\": \"object\",\n",
    "            \"last_sysbp\": \"object\",\n",
    "            \"first_sysbp\": \"object\",\n",
    "            \"last_temp\": \"object\",\n",
    "            \"first_temp\": \"object\",\n",
    "            \"last_resprate\": \"object\",\n",
    "            \"first_resprate\": \"object\",\n",
    "            \"last_heartrate\": \"object\",\n",
    "            \"first_heartrate\": \"object\"\n",
    "        }\n",
    "    },\n",
    "     {\n",
    "        \"name\": \"antibiotic_class_exposure\",\n",
    "        \"path\": \"microbiology_cultures_antibiotic_class_exposure.csv\",\n",
    "        \"merge_on\": linked_features, \n",
    "        \"dtype\": {\n",
    "            \"medication_category\": \"object\",\n",
    "            \"medication_name\": \"object\",\n",
    "            \"antibiotic_class\": \"object\",\n",
    "            \"time_to_culturetime\": \"Int64\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"antibiotic_subtype_exposure\",\n",
    "        \"path\": \"microbiology_cultures_antibiotic_subtype_exposure.csv\",\n",
    "        \"merge_on\": linked_features, \n",
    "        \"dtype\": {\n",
    "            \"medication_category\": \"object\",\n",
    "            \"medication_name\": \"object\",\n",
    "            \"antibiotic_subtype\": \"object\",\n",
    "            \"antibiotic_subtype_category\": \"object\",\n",
    "            \"medication_time_to_cultureTime\": \"Int64\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"prior_infecting_organism\",\n",
    "        \"path\": \"microbiology_culture_prior_infecting_organism.csv\",\n",
    "        \"merge_on\": linked_features, \n",
    "        \"dtype\": {\n",
    "            \"prior_organism\": \"object\",\n",
    "            \"prior_infecting_organism_days_to_culutre\": \"Int64\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"cultures_comorbidity\",\n",
    "        \"path\": \"microbiology_cultures_comorbidity.csv\",\n",
    "        \"merge_on\": linked_features, \n",
    "        \"dtype\": {\n",
    "            \"comorbidity_component\": \"object\",\n",
    "            \"comorbidity_component_start_days_culture\": \"Int64\",\n",
    "            \"comorbidity_component_end_days_culture\": \"float64\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"cultures_priorprocedures\",\n",
    "        \"path\": \"microbiology_cultures_priorprocedures.csv\",\n",
    "        \"merge_on\": linked_features, \n",
    "        \"dtype\": {\n",
    "            \"procedure_description\": \"object\",\n",
    "            \"procedure_time_to_culturetime\": \"Int64\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"adi_scores\",\n",
    "        \"path\": \"microbiology_cultures_adi_scores.csv\",\n",
    "        \"merge_on\": linked_features, \n",
    "        \"dtype\": {\n",
    "            \"adi_score\": \"object\",\n",
    "            \"adi_state_rank\": \"object\"\n",
    "        }\n",
    "    },\n",
    "    # {\n",
    "    #     \"name\": \"nursing_home_visits\",\n",
    "    #     \"path\": \"microbiology_cultures_adi_scores.csv\",\n",
    "    #     \"merge_on\": linked_features, \n",
    "    #     \"dtype\": {\n",
    "    #         \"nursing_home_visit_culture\": \"Int64\"\n",
    "    #     }\n",
    "    # },\n",
    "    {\n",
    "        \"name\": \"implied_susceptibility\",\n",
    "        \"path\": \"microbiology_cultures_implied_susceptibility.csv\",\n",
    "        \"merge_on\": linked_features[:3], \n",
    "        \"dtype\": {\n",
    "            \"organism\": \"object\",\n",
    "            \"antibiotic\": \"object\",\n",
    "            \"susceptibility\": \"object\",\n",
    "            \"implied_susceptibility\": \"object\"\n",
    "        }\n",
    "    }\n",
    "    #, {\n",
    "    #     \"name\": \"implied_susceptibility_rules\",\n",
    "    #     \"path\": \"microbiology_cultures_implied_susceptibility.csv\",\n",
    "    #     \"merge_on\": None , \n",
    "    #     \"dtype\": {\n",
    "    #         \"Organism\": \"object\",\n",
    "    #         \"Antibiotic\": \"object\",\n",
    "    #         \"Susceptibility\": \"object\",\n",
    "    #     }\n",
    "    # }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbc09aa5-628f-4f89-a84f-ebdbae9612a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample saved: new_sample_tow/cultures_cohort.parquet\n",
      "Sample saved: new_sample_tow/ward_info.parquet\n",
      "Sample saved: new_sample_tow/prior_med.parquet\n",
      "Sample saved: new_sample_tow/microbial_resistance.parquet\n",
      "Sample saved: new_sample_tow/cultures_demographics.parquet\n",
      "Sample saved: new_sample_tow/cultures_labs.parquet\n",
      "Sample saved: new_sample_tow/cultures_vitals.parquet\n",
      "Sample saved: new_sample_tow/antibiotic_class_exposure.parquet\n",
      "Sample saved: new_sample_tow/antibiotic_subtype_exposure.parquet\n",
      "Sample saved: new_sample_tow/prior_infecting_organism.parquet\n",
      "Sample Saved: new_sample_tow/cultures_comorbidity.parquet\n",
      "Sample saved: new_sample_tow/cultures_priorprocedures.parquet\n",
      "Sample saved: new_sample_tow/adi_scores.parquet\n",
      "Sample saved: new_sample_tow/implied_susceptibility.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "input_folder = 'doi_10_5061_dryad_jq2bvq8kp__v20250411/'\n",
    "output_file = 'new_sample_tow/'\n",
    "linked_features = ['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded', 'order_time_jittered_utc']\n",
    "\n",
    "os.makedirs(output_file, exist_ok=True)\n",
    "\n",
    "pat_ids = pd.read_csv(input_folder + files_info[0]['path'], usecols=['anon_id'] ).drop_duplicates().sample(n=100, random_state=42)\n",
    "\n",
    "for file in files_info:\n",
    "    size_bytes = os.path.getsize(input_folder + file['path'])\n",
    "    size_gb = size_bytes / (1024 ** 3) \n",
    "    if (size_gb < 2):\n",
    "        df = pd.read_csv(input_folder + file['path'], dtype = file['dtype'] , na_values=['Null'])\n",
    "        df = df[df['anon_id'].isin(pat_ids['anon_id'])]\n",
    "        df.to_parquet(output_file + file['name'] + '.parquet',  engine='pyarrow', index=False )\n",
    "        print(f\"Sample saved: {output_file + file['name'] + '.parquet'}\")\n",
    "    else:\n",
    "        chunk_size = 1_000_000\n",
    "        filtered_chunks = []\n",
    "        for chunk in pd.read_csv(input_folder + file['path'], dtype=file['dtype'], na_values=['Null'], chunksize=chunk_size):\n",
    "            filtered_chunk = chunk[chunk['anon_id'].isin(pat_ids['anon_id'])]\n",
    "            filtered_chunks.append(filtered_chunk)\n",
    "    \n",
    "        if filtered_chunks:\n",
    "            df = pd.concat(filtered_chunks, ignore_index=True)\n",
    "            df.to_parquet(output_file + file['name'] + '.parquet', engine='pyarrow',  index=False)\n",
    "            print(f\"Sample Saved: {output_file + file['name']}.parquet\")\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a0e3f64-b1dd-438e-8586-fa8ba8533226",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file new_sample_tow/cultures_cohort.parquet:  \n",
      "     anon_id  pat_enc_csn_id_coded  order_proc_id_coded  \\\n",
      "0  JC1318312          131013741576            383925524   \n",
      "1  JC6248701          131326546225            774526552   \n",
      "2  JC1245822          131002330064            355483042   \n",
      "3  JC1245822          131002330064            355483042   \n",
      "4  JC1084866          131342950075            827884512   \n",
      "\n",
      "     order_time_jittered_utc ordering_mode culture_description  was_positive  \\\n",
      "0  2011-06-09 14:21:00+00:00     Inpatient               BLOOD             1   \n",
      "1  2022-02-26 22:31:00+00:00     Inpatient               URINE             1   \n",
      "2  2009-09-07 12:15:00+00:00     Inpatient               BLOOD             1   \n",
      "3  2009-09-07 12:15:00+00:00     Inpatient               BLOOD             1   \n",
      "4  2022-10-08 00:30:00+00:00    Outpatient               URINE             1   \n",
      "\n",
      "                organism    antibiotic susceptibility  \n",
      "0  STAPHYLOCOCCUS AUREUS  Erythromycin    Susceptible  \n",
      "1       ESCHERICHIA COLI   Ceftazidime    Susceptible  \n",
      "2  KLEBSIELLA PNEUMONIAE  Levofloxacin    Susceptible  \n",
      "3  KLEBSIELLA PNEUMONIAE     Meropenem    Susceptible  \n",
      "4       ESCHERICHIA COLI  Levofloxacin    Susceptible  \n",
      "-----------------------------------------------\n",
      "file new_sample_tow/ward_info.parquet:  \n",
      "     anon_id  pat_enc_csn_id_coded  order_proc_id_coded  \\\n",
      "0  JC2078594          131344326838            836132730   \n",
      "1   JC643891          131355067197            886030731   \n",
      "2   JC643652          131356978988            885606697   \n",
      "3  JC2078594          131359646757            896632201   \n",
      "4  JC1661212          131090452781            465939738   \n",
      "\n",
      "     order_time_jittered_utc  hosp_ward_IP  hosp_ward_OP  hosp_ward_ER  \\\n",
      "0  2022-11-09 08:00:00+00:00             0             1             0   \n",
      "1  2023-06-19 18:28:00+00:00             0             1             0   \n",
      "2  2023-06-09 18:06:00+00:00             0             1             0   \n",
      "3  2023-07-19 07:00:00+00:00             0             1             0   \n",
      "4  2015-06-01 19:20:00+00:00             0             1             0   \n",
      "\n",
      "   hosp_ward_ICU  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "-----------------------------------------------\n",
      "file new_sample_tow/prior_med.parquet:  \n",
      "     anon_id  pat_enc_csn_id_coded  order_proc_id_coded  \\\n",
      "0  JC1990504          131337031787            808253042   \n",
      "1  JC1047194          131238698886            536685332   \n",
      "2  JC1047194          131238698886            536685332   \n",
      "3  JC1047194          131238698886            536685332   \n",
      "4  JC1047194          131239470508            538491343   \n",
      "\n",
      "     order_time_jittered_utc medication_name  medication_time_to_culturetime  \\\n",
      "0  2022-07-04 07:00:00+00:00      Ampicillin                              43   \n",
      "1  2017-10-10 22:34:00+00:00       Cefazolin                            2084   \n",
      "2  2017-10-10 22:34:00+00:00       Cefazolin                            1051   \n",
      "3  2017-10-10 22:34:00+00:00       Cefazolin                            1078   \n",
      "4  2017-10-30 22:35:00+00:00       Cefazolin                            1071   \n",
      "\n",
      "  medication_category  \n",
      "0                AMP1  \n",
      "1                 CEF  \n",
      "2                 CEF  \n",
      "3                 CEF  \n",
      "4                 CEF  \n",
      "-----------------------------------------------\n",
      "file new_sample_tow/microbial_resistance.parquet:  \n",
      "     anon_id  pat_enc_csn_id_coded  order_proc_id_coded  \\\n",
      "0   JC737187          131205798069            512106652   \n",
      "1  JC1103383          131007790702            360179829   \n",
      "2  JC1103383          131003800503            354938600   \n",
      "3  JC1695988          131038374161            444426696   \n",
      "4  JC1969010          131249094404            557289056   \n",
      "\n",
      "     order_time_jittered_utc  \\\n",
      "0  2016-11-25 17:54:00+00:00   \n",
      "1  2009-11-17 20:08:00+00:00   \n",
      "2  2009-07-17 18:42:00+00:00   \n",
      "3  2014-08-26 11:32:00+00:00   \n",
      "4  2018-04-13 13:49:00+00:00   \n",
      "\n",
      "                                            organism  antibiotic  \\\n",
      "0          CITROBACTER KOSERI (CARBAPENEM RESISTANT)  Ampicillin   \n",
      "1                              KLEBSIELLA PNEUMONIAE  Ampicillin   \n",
      "2                              KLEBSIELLA PNEUMONIAE  Ampicillin   \n",
      "3  CITROBACTER FREUNDII COMPLEX (CARBAPENEM RESIS...  Ampicillin   \n",
      "4                                   ESCHERICHIA COLI  Ampicillin   \n",
      "\n",
      "   resistant_time_to_culturetime  \n",
      "0                            891  \n",
      "1                            122  \n",
      "2                            160  \n",
      "3                             24  \n",
      "4                            259  \n",
      "-----------------------------------------------\n",
      "file new_sample_tow/cultures_demographics.parquet:  \n",
      "     anon_id  pat_enc_csn_id_coded  order_proc_id_coded          age gender\n",
      "0  JC1066598              15495600            325629864  18-24 years      1\n",
      "1  JC2497119          131002216467            353843746  25-34 years      1\n",
      "2  JC2497119          131007853609            360448616  25-34 years      1\n",
      "3  JC2497119          131007853609            360448617  25-34 years      1\n",
      "4  JC2497119          131002216467            353843747  25-34 years      1\n",
      "-----------------------------------------------\n",
      "file new_sample_tow/cultures_labs.parquet:  \n",
      "     anon_id  pat_enc_csn_id_coded  order_proc_id_coded  Period_Day Q75_wbc  \\\n",
      "0  JC2497119          131311288212            728746621          14    None   \n",
      "1   JC707016          131355217504            879154486          14     8.8   \n",
      "2  JC2045445          131358230466            901631132          14    10.8   \n",
      "3  JC2497119          131029054460            432532560          14    21.3   \n",
      "4   JC707016          131298884515            693759695          14    16.1   \n",
      "\n",
      "  Q25_wbc median_wbc  Q25_neutrophils  Q75_neutrophils  median_neutrophils  \\\n",
      "0    None       None              NaN              NaN                 NaN   \n",
      "1     6.6        8.8              0.0             81.1                 0.0   \n",
      "2     7.0        7.4              NaN              NaN                 NaN   \n",
      "3    13.0       13.0              NaN              NaN                 NaN   \n",
      "4    12.7       12.7              NaN              NaN                 NaN   \n",
      "\n",
      "   ...  last_plt  first_plt  last_hgb first_hgb last_lymphocytes  \\\n",
      "0  ...      None       None      None      None             None   \n",
      "1  ...      None       None      None      None             None   \n",
      "2  ...      None       None      None      None             None   \n",
      "3  ...      None       None      None      None             None   \n",
      "4  ...      None       None      None      None             None   \n",
      "\n",
      "  first_lymphocytes last_neutrophils first_neutrophils last_wbc first_wbc  \n",
      "0              None             None              None     None      None  \n",
      "1              None             None              None      6.6      None  \n",
      "2              None             None              None     10.6      None  \n",
      "3              None             None              None     None      None  \n",
      "4              None             None              None     None      None  \n",
      "\n",
      "[5 rows x 59 columns]\n",
      "-----------------------------------------------\n",
      "file new_sample_tow/cultures_vitals.parquet:  \n",
      "     anon_id  pat_enc_csn_id_coded  order_proc_id_coded Q25_heartrate  \\\n",
      "0  JC1245822          131002330064            355483045          53.0   \n",
      "1   JC574079          131240280777            540552321         104.0   \n",
      "2  JC1318312          131015533825            389933893          82.0   \n",
      "3  JC1744217          131067102397            456416010          66.0   \n",
      "4  JC2763351          131280573383            643792430          66.0   \n",
      "\n",
      "  Q75_heartrate median_heartrate Q25_resprate Q75_resprate median_resprate  \\\n",
      "0          61.0             58.0         18.0         18.0            18.0   \n",
      "1         108.0            105.0         21.0         24.0            23.0   \n",
      "2          99.0             90.0         16.0         16.0            16.0   \n",
      "3          75.0             71.0         18.0         20.0            18.0   \n",
      "4          83.0             71.0         12.0         12.0            12.0   \n",
      "\n",
      "  Q25_temp  ... first_diasbp last_diasbp  last_sysbp  first_sysbp  last_temp  \\\n",
      "0     97.2  ...         None        70.0       145.0         None       None   \n",
      "1    100.5  ...         88.0        None        None        173.0      100.5   \n",
      "2     99.1  ...         None        None        None         None       99.1   \n",
      "3     98.0  ...         None        None        None         None       None   \n",
      "4     97.9  ...         None        None        None         None       98.8   \n",
      "\n",
      "   first_temp  last_resprate  first_resprate last_heartrate first_heartrate  \n",
      "0        None           None            None           None            58.0  \n",
      "1        None           None            None           None            None  \n",
      "2        None           None            18.0           None            None  \n",
      "3        None           16.0            18.0           None            None  \n",
      "4        None           None            None           None            67.0  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "-----------------------------------------------\n",
      "file new_sample_tow/antibiotic_class_exposure.parquet:  \n",
      "     anon_id  pat_enc_csn_id_coded  order_proc_id_coded  \\\n",
      "0  JC2497119          131176735433            485362582   \n",
      "1  JC1318312          131269212582            613808961   \n",
      "2  JC2497119          131034561120            440187377   \n",
      "3  JC2497119          131317474485            746538708   \n",
      "4   JC707016          131340236223            819172424   \n",
      "\n",
      "     order_time_jittered_utc medication_category  \\\n",
      "0  2016-01-13 21:38:00+00:00                 RIF   \n",
      "1  2019-06-21 21:08:00+00:00                 SUL   \n",
      "2  2014-04-26 21:47:00+00:00                 SUL   \n",
      "3  2021-08-16 22:40:00+00:00                 PIP   \n",
      "4  2022-09-11 10:18:00+00:00                 PIP   \n",
      "\n",
      "                  medication_name        antibiotic_class  time_to_culturetime  \n",
      "0                       Rifaximin               Ansamycin                 1077  \n",
      "1   Sulfamethoxazole-Trimethoprim  Combination Antibiotic                 2931  \n",
      "2   Sulfamethoxazole-Trimethoprim  Combination Antibiotic                  156  \n",
      "3  Piperacillin-Tazobactam-Dextrs             Beta Lactam                 1595  \n",
      "4  Piperacillin-Tazobactam-Dextrs             Beta Lactam                   40  \n",
      "-----------------------------------------------\n",
      "file new_sample_tow/antibiotic_subtype_exposure.parquet:  \n",
      "     anon_id  pat_enc_csn_id_coded  order_proc_id_coded  \\\n",
      "0  JC2497119          131282557375            649701380   \n",
      "1   JC737187          131030291551            436136973   \n",
      "2  JC2497119          131203879461            508295026   \n",
      "3  JC2497119          131340920609            821122991   \n",
      "4  JC2497119          131328636299            781103197   \n",
      "\n",
      "     order_time_jittered_utc medication_category      medication_name  \\\n",
      "0  2020-01-07 21:37:00+00:00                 SIL  Silver Sulfadiazine   \n",
      "1  2014-02-21 20:35:00+00:00                 KEF               Keflex   \n",
      "2  2016-10-08 02:46:00+00:00                LEV2             Levaquin   \n",
      "3  2022-09-12 19:25:00+00:00                 BAC           Bactrim Ds   \n",
      "4  2022-02-15 20:34:00+00:00                 DAP              Dapsone   \n",
      "\n",
      "   antibiotic_subtype antibiotic_subtype_category  \\\n",
      "0         Sulfonamide                         SUL   \n",
      "1  Cephalosporin Gen1                        CEP1   \n",
      "2     Fluoroquinolone                         FLQ   \n",
      "3   Sulfonamide Combo                        SULC   \n",
      "4         Sulfonamide                         SUL   \n",
      "\n",
      "   medication_time_to_cultureTime  \n",
      "0                             578  \n",
      "1                            1194  \n",
      "2                            1052  \n",
      "3                            2674  \n",
      "4                            1674  \n",
      "-----------------------------------------------\n",
      "file new_sample_tow/prior_infecting_organism.parquet:  \n",
      "     anon_id  pat_enc_csn_id_coded  order_proc_id_coded  \\\n",
      "0  JC1047194          131239470508            538491343   \n",
      "1  JC1047194          131334449761            799838619   \n",
      "2  JC1047194          131334449761            799838619   \n",
      "3  JC1047194          131334449761            799838620   \n",
      "4  JC1084866          131345617646            839299241   \n",
      "\n",
      "     order_time_jittered_utc  prior_organism  \\\n",
      "0  2017-10-30 22:35:00+00:00  Staphylococcus   \n",
      "1  2022-07-12 20:02:00+00:00            CONS   \n",
      "2  2022-07-12 20:02:00+00:00  Staphylococcus   \n",
      "3  2022-07-12 20:02:00+00:00  Staphylococcus   \n",
      "4  2022-11-18 18:31:00+00:00     Escherichia   \n",
      "\n",
      "   prior_infecting_organism_days_to_culutre  \n",
      "0                                      1061  \n",
      "1                                      1711  \n",
      "2                                       634  \n",
      "3                                       634  \n",
      "4                                        39  \n",
      "-----------------------------------------------\n",
      "file new_sample_tow/cultures_comorbidity.parquet:  \n",
      "     anon_id  pat_enc_csn_id_coded  order_proc_id_coded  \\\n",
      "0   JC574079          131240280777            540552320   \n",
      "1  JC2497119          131093967311            468951774   \n",
      "2  JC2045445          131358230466            901631131   \n",
      "3  JC2497119          131039731084            444563225   \n",
      "4  JC2497119          131328636299            781103198   \n",
      "\n",
      "     order_time_jittered_utc  \\\n",
      "0  2017-10-02 23:08:00+00:00   \n",
      "1  2015-06-26 00:07:00+00:00   \n",
      "2  2023-09-14 23:57:00+00:00   \n",
      "3  2014-07-08 19:21:00+00:00   \n",
      "4  2022-02-15 20:34:00+00:00   \n",
      "\n",
      "                               comorbidity_component  \\\n",
      "0                        Cornea and external disease   \n",
      "1                                      Osteomyelitis   \n",
      "2  Adverse effects of drugs and medicaments, init...   \n",
      "3                                        Invalid PDX   \n",
      "4  Complication of other surgical or medical care...   \n",
      "\n",
      "   comorbidity_component_start_days_culture  \\\n",
      "0                                       389   \n",
      "1                                       555   \n",
      "2                                       125   \n",
      "3                                        53   \n",
      "4                                      2521   \n",
      "\n",
      "   comorbidity_component_end_days_culture  \n",
      "0                                     NaN  \n",
      "1                                     NaN  \n",
      "2                                     NaN  \n",
      "3                                     NaN  \n",
      "4                                     NaN  \n",
      "-----------------------------------------------\n",
      "file new_sample_tow/cultures_priorprocedures.parquet:  \n",
      "     anon_id  pat_enc_csn_id_coded  order_proc_id_coded  \\\n",
      "0  JC1047194          131239470508            538491343   \n",
      "1  JC1047194          131248301874            558066483   \n",
      "2  JC1047194          131294633486            682386026   \n",
      "3  JC1155550          131231332318            527135144   \n",
      "4  JC1155550          131247545701            553400737   \n",
      "\n",
      "     order_time_jittered_utc procedure_description  \\\n",
      "0  2017-10-30 22:35:00+00:00    surgical_procedure   \n",
      "1  2018-05-01 17:58:00+00:00                   cvc   \n",
      "2  2020-10-12 18:26:00+00:00                   cvc   \n",
      "3  2017-05-22 08:27:00+00:00              mechvent   \n",
      "4  2018-02-15 06:59:00+00:00              mechvent   \n",
      "\n",
      "   procedure_time_to_culturetime  \n",
      "0                           2104  \n",
      "1                            180  \n",
      "2                           3246  \n",
      "3                           2179  \n",
      "4                           2441  \n",
      "-----------------------------------------------\n",
      "file new_sample_tow/adi_scores.parquet:  \n",
      "     anon_id  pat_enc_csn_id_coded  order_proc_id_coded  \\\n",
      "0  JC6523156          131360434368            898550994   \n",
      "1  JC2851324          131271447495            617213603   \n",
      "2  JC1066598              15495600            325629864   \n",
      "3  JC6524522          131360606175            899099156   \n",
      "4  JC2714795          131283846399            653994552   \n",
      "\n",
      "     order_time_jittered_utc adi_score adi_state_rank  \n",
      "0  2023-09-16 13:35:00+00:00      None           None  \n",
      "1  2019-05-29 22:01:00+00:00      None           None  \n",
      "2  2008-06-03 03:31:00+00:00      None           None  \n",
      "3  2023-09-16 07:18:00+00:00      None           None  \n",
      "4  2020-03-20 23:02:00+00:00      None           None  \n",
      "-----------------------------------------------\n",
      "file new_sample_tow/implied_susceptibility.parquet:  \n",
      "     anon_id  pat_enc_csn_id_coded  order_proc_id_coded  \\\n",
      "0   JC737187          131205798069            514031235   \n",
      "1  JC2497119          131317474485            746538709   \n",
      "2  JC1318312          131013741576            383925524   \n",
      "3  JC1245822          131002330064            355483042   \n",
      "4  JC1245822          131002330064            355483042   \n",
      "\n",
      "                          organism                     antibiotic  \\\n",
      "0  ACINETOBACTER BAUMANNII COMPLEX                    minocycline   \n",
      "1            STAPHYLOCOCCUS AUREUS                     Daptomycin   \n",
      "2            STAPHYLOCOCCUS AUREUS  Trimethoprim/Sulfamethoxazole   \n",
      "3            KLEBSIELLA PNEUMONIAE                     Cefotaxime   \n",
      "4            KLEBSIELLA PNEUMONIAE                      Cefotetan   \n",
      "\n",
      "  susceptibility implied_susceptibility  \n",
      "0           None              Resistant  \n",
      "1    Susceptible                   None  \n",
      "2    Susceptible                   None  \n",
      "3    Susceptible                   None  \n",
      "4    Susceptible                   None  \n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "output_file = 'new_sample_tow/'\n",
    "for file in files_info:\n",
    "    df = pd.read_parquet(output_file + file['name'] + '.parquet')\n",
    "    print(f\"file {output_file + file['name'] + '.parquet'}:  \")\n",
    "    print(df.head())\n",
    "    print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bad39d09-52f1-42e5-8090-086d15d6f711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ordering_mode': 'object', 'culture_description': 'object', 'was_positive': 'Int64', 'organism': 'object', 'antibiotic': 'object', 'susceptibility': 'object'}\n",
      "Base file: new_sample_tow/cultures_cohort.parquet is loaded\n",
      "Start merge with: new_sample_tow/ward_info.parquet \n",
      "Start merge with: new_sample_tow/prior_med.parquet \n",
      "Start merge with: new_sample_tow/microbial_resistance.parquet \n",
      "Start merge with: new_sample_tow/cultures_demographics.parquet \n",
      "Start merge with: new_sample_tow/cultures_labs.parquet \n",
      "Start merge with: new_sample_tow/cultures_vitals.parquet \n",
      "Start merge with: new_sample_tow/antibiotic_class_exposure.parquet \n",
      "Start merge with: new_sample_tow/antibiotic_subtype_exposure.parquet \n",
      "Start merge with: new_sample_tow/prior_infecting_organism.parquet \n",
      "Start merge with: new_sample_tow/cultures_comorbidity.parquet \n",
      "Start merge with: new_sample_tow/cultures_priorprocedures.parquet \n",
      "Start merge with: new_sample_tow/adi_scores.parquet \n",
      "Start merge with: new_sample_tow/implied_susceptibility.parquet \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import dask as d\n",
    "\n",
    "\n",
    "sample_folder = 'new_sample_tow/'\n",
    "merged_folder = 'merged_sample_tow/'\n",
    "\n",
    "os.makedirs(merged_folder, exist_ok=True)\n",
    "\n",
    "merged_dtype = files_info[0]['dtype']\n",
    "print(merged_dtype)\n",
    "base_sample = pd.read_parquet(sample_folder + files_info[0]['name'] + '.parquet', engine='pyarrow')\n",
    "base_sample = base_sample.astype(merged_dtype)\n",
    "\n",
    "print(f\"Base file: {sample_folder + files_info[0]['name'] + '.parquet'} is loaded\")\n",
    "\n",
    "def get_df_size_mb(df):\n",
    "    return df.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "\n",
    "def getDatatype(file):\n",
    "    all_keys = {'anon_id':'object',\n",
    "               'pat_enc_csn_id_coded':'Int64',\n",
    "               'order_proc_id_coded':'Int64',\n",
    "               'order_time_jittered_utc':'object'}\n",
    "    part_keys = {\n",
    "        'anon_id':'object',\n",
    "               'pat_enc_csn_id_coded':'Int64',\n",
    "               'order_proc_id_coded':'Int64'\n",
    "    }\n",
    "    for f in files_info:\n",
    "        if f['name']== file:\n",
    "            if len(f['merge_on']) == 4:\n",
    "                all_keys.update(f['dtype'])\n",
    "                return all_keys\n",
    "            else:\n",
    "                part_keys.update(f['dtype'])\n",
    "                return part_keys\n",
    "\n",
    "def write_parquet(df1, filename, mode='w'):\n",
    "    table = pa.Table.from_pandas(df1)\n",
    "    if mode == 'w':\n",
    "        pq.write_table(table, filename)\n",
    "    elif mode == 'a':\n",
    "        try:\n",
    "            existing_table = pq.read_table(filename)\n",
    "            combined_table = pa.concat_tables([existing_table, table])\n",
    "            pq.write_table(combined_table, filename)\n",
    "        except FileNotFoundError:\n",
    "            # If file doesn't exist, just write new table\n",
    "            pq.write_table(table, filename)\n",
    "\n",
    "\n",
    "MAX_MEMORY_MB = 100\n",
    "mode = 'w'\n",
    "saved = False\n",
    "\n",
    "for file in files_info[1:]:\n",
    "    dtype = getDatatype(file['name'])\n",
    "    print(f\"Start merge with: {sample_folder + file['name'] + '.parquet'} \")\n",
    "    df = pd.read_parquet(sample_folder + file['name'] + '.parquet' )\n",
    "    df = df.astype(dtype)\n",
    "\n",
    "    if get_df_size_mb(base_sample) > MAX_MEMORY_MB:\n",
    "        base_sample.to_parquet(merged_folder + 'merged_ARMD.parquet' , engine='pyarrow', index=False)\n",
    "        saved = True\n",
    "        base_sample = pd.DataFrame()\n",
    "    \n",
    "    merged_dtype.update(dtype)\n",
    "    \n",
    "    if saved:\n",
    "        parquet_file = pq.ParquetFile(merged_folder + 'merged_ARMD.parquet')\n",
    "        for i in range(parquet_file.num_row_groups):\n",
    "            chunk = parquet_file.read_row_group(i).to_pandas()\n",
    "            temp = chunk.merge(df, how = 'left', on = file['merge_on'], suffixes=('', '_right') )\n",
    "            temp = temp.drop(columns=[col for col in temp.columns if col.endswith('_right')])\n",
    "            temp = temp.astype(merged_dtype)\n",
    "            write_parquet(temp, merged_folder + 'temp_merged_ARMD.parquet', mode=mode)\n",
    "            mode = 'a'\n",
    "    else:\n",
    "        base_sample = base_sample.merge(df, how = 'left', on = file['merge_on'] , suffixes=('', '_right'))\n",
    "        base_sample = base_sample.drop(columns=[col for col in base_sample.columns if col.endswith('_right')])\n",
    "\n",
    "    mode = 'w'\n",
    "    \n",
    "    if saved:\n",
    "        parquet_file = pq.ParquetFile(merged_folder + 'temp_merged_ARMD.parquet')\n",
    "        for i in range(parquet_file.num_row_groups):\n",
    "            chunk = parquet_file.read_row_group(i).to_pandas()\n",
    "            chunk = chunk.astype(merged_dtype)\n",
    "            write_parquet(chunk, merged_folder + 'merged_ARMD.parquet', mode=mode)\n",
    "            mode = 'a'\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a53d13b9-db56-4255-bf25-410d6efba07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load base file: cultures_cohort\n",
      "Merging file: ward_info\n",
      "Merging file: prior_med\n",
      "Merging file: microbial_resistance\n",
      "Merging file: cultures_demographics\n",
      "Merging file: cultures_labs\n",
      "Merging file: cultures_vitals\n",
      "Merging file: antibiotic_class_exposure\n",
      "Merging file: antibiotic_subtype_exposure\n",
      "Merging file: prior_infecting_organism\n",
      "Merging file: cultures_comorbidity\n",
      "Merging file: cultures_priorprocedures\n",
      "Merging file: adi_scores\n",
      "Merging file: nursing_home_visits\n",
      "Merging file: implied_susceptibility\n",
      "\n",
      "Writing merged data to: merged_sample_tow/merged_result.parquet\n",
      "\n",
      " Alhamdulillah the merged_sample_tow/merged_result.parquet merged and saved ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\multi.py:169: UserWarning: Merging dataframes with merge column data type mismatches: \n",
      "+--------------------------------------------------------+------------+-------------+\n",
      "| Merge columns                                          | left dtype | right dtype |\n",
      "+--------------------------------------------------------+------------+-------------+\n",
      "| ('anon_id', 'anon_id')                                 | string     | object      |\n",
      "| ('order_time_jittered_utc', 'order_time_jittered_utc') | string     | object      |\n",
      "+--------------------------------------------------------+------------+-------------+\n",
      "Cast dtypes explicitly to avoid unexpected results.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\multi.py:169: UserWarning: Merging dataframes with merge column data type mismatches: \n",
      "+------------------------+------------+-------------+\n",
      "| Merge columns          | left dtype | right dtype |\n",
      "+------------------------+------------+-------------+\n",
      "| ('anon_id', 'anon_id') | object     | string      |\n",
      "+------------------------+------------+-------------+\n",
      "Cast dtypes explicitly to avoid unexpected results.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\multi.py:169: UserWarning: Merging dataframes with merge column data type mismatches: \n",
      "+------------------------+------------+-------------+\n",
      "| Merge columns          | left dtype | right dtype |\n",
      "+------------------------+------------+-------------+\n",
      "| ('anon_id', 'anon_id') | object     | string      |\n",
      "+------------------------+------------+-------------+\n",
      "Cast dtypes explicitly to avoid unexpected results.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\multi.py:169: UserWarning: Merging dataframes with merge column data type mismatches: \n",
      "+------------------------+------------+-------------+\n",
      "| Merge columns          | left dtype | right dtype |\n",
      "+------------------------+------------+-------------+\n",
      "| ('anon_id', 'anon_id') | object     | string      |\n",
      "+------------------------+------------+-------------+\n",
      "Cast dtypes explicitly to avoid unexpected results.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\multi.py:169: UserWarning: Merging dataframes with merge column data type mismatches: \n",
      "+--------------------------------------------------------+------------+-------------+\n",
      "| Merge columns                                          | left dtype | right dtype |\n",
      "+--------------------------------------------------------+------------+-------------+\n",
      "| ('anon_id', 'anon_id')                                 | object     | string      |\n",
      "| ('order_time_jittered_utc', 'order_time_jittered_utc') | object     | string      |\n",
      "+--------------------------------------------------------+------------+-------------+\n",
      "Cast dtypes explicitly to avoid unexpected results.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\multi.py:169: UserWarning: Merging dataframes with merge column data type mismatches: \n",
      "+--------------------------------------------------------+------------+-------------+\n",
      "| Merge columns                                          | left dtype | right dtype |\n",
      "+--------------------------------------------------------+------------+-------------+\n",
      "| ('anon_id', 'anon_id')                                 | object     | string      |\n",
      "| ('order_time_jittered_utc', 'order_time_jittered_utc') | object     | string      |\n",
      "+--------------------------------------------------------+------------+-------------+\n",
      "Cast dtypes explicitly to avoid unexpected results.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\multi.py:169: UserWarning: Merging dataframes with merge column data type mismatches: \n",
      "+--------------------------------------------------------+------------+-------------+\n",
      "| Merge columns                                          | left dtype | right dtype |\n",
      "+--------------------------------------------------------+------------+-------------+\n",
      "| ('anon_id', 'anon_id')                                 | object     | string      |\n",
      "| ('order_time_jittered_utc', 'order_time_jittered_utc') | object     | string      |\n",
      "+--------------------------------------------------------+------------+-------------+\n",
      "Cast dtypes explicitly to avoid unexpected results.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import os\n",
    "\n",
    "sample_folder = 'new_sample_tow/'\n",
    "merged_folder = 'merged_sample_tow/'\n",
    "os.makedirs(merged_folder, exist_ok=True)\n",
    "\n",
    "def getMergOn(file):\n",
    "    all_keys = {\n",
    "        'anon_id': 'object',\n",
    "        'pat_enc_csn_id_coded': 'Int64',\n",
    "        'order_proc_id_coded': 'Int64',\n",
    "        'order_time_jittered_utc': 'object'\n",
    "    }\n",
    "    part_keys = {\n",
    "        'anon_id': 'object',  \n",
    "        'pat_enc_csn_id_coded': 'Int64',\n",
    "        'order_proc_id_coded': 'Int64'\n",
    "    }\n",
    "    for f in files_info:\n",
    "        if f['name'] == file:\n",
    "            return all_keys if len(f['merge_on']) == 4 else part_keys\n",
    "\n",
    "file_df_pairs = [(file['name'], dd.read_parquet(\n",
    "    os.path.join(sample_folder, file['name'] + '.parquet'),\n",
    "    dtype=file['dtype']\n",
    ")) for file in files_info]\n",
    "\n",
    "# Start with base file\n",
    "merged_df = file_df_pairs[0][1]\n",
    "print(f\"Load base file: {file_df_pairs[0][0]}\")\n",
    "\n",
    "# Merge sequentially\n",
    "for file_path, df in file_df_pairs[1:]:\n",
    "    print(f\"Merging file: {file_path}\")\n",
    "    merg_on = getMergOn(file_path)\n",
    "    merged_df = merged_df.merge(df, how='left', on=merg_on)\n",
    "\n",
    "\n",
    "# Write to parquet\n",
    "output_path = os.path.join(merged_folder, 'merged_result.parquet')\n",
    "merged_df = merged_df.repartition(partition_size=\"50MB\")  # or npartitions=500\n",
    "# merged_df = merged_df.persist()  # only if RAM allows\n",
    "print(f\"\\nWriting merged data to: {output_path}\")\n",
    "write_task = merged_df.to_parquet(\n",
    "    output_path,\n",
    "    engine='pyarrow',\n",
    "    compression='snappy',\n",
    "    write_index=False,\n",
    "    write_metadata_file=False,\n",
    "    compute=False\n",
    ")\n",
    "print(f\"\\n Alhamdulillah the {output_path} merged and saved ✅\")\n",
    "# yarb yshteghel ana t3abt :(\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4cde7c-7ac5-4ddf-8146-bdbda123c222",
   "metadata": {},
   "source": [
    "# Left join USING Dask: File by File. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db8634-9525-41d7-bf51-324a22b909fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "sample_folder = 'new_sample_one/'\n",
    "sample_files = glob.glob(sample_folder + \"*.parquet\")\n",
    "for file in sample_files:\n",
    "    print(os.path.basename(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb764ca-567f-4df6-bab1-c5b03cf2bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import glob\n",
    "import os \n",
    "\n",
    "sample_folder = 'new_sample_one/'\n",
    "merged_folder = 'merged_sample_one/'\n",
    "linked_features = ['anon_id', 'pat_enc_csn_id_coded', 'order_proc_id_coded', 'order_time_jittered_utc']\n",
    "\n",
    "os.makedirs(merged_folder, exist_ok=True)\n",
    "\n",
    "sample_files = glob.glob(sample_folder + \"*.parquet\")\n",
    "\n",
    "print(f'left join, left:{os.path.basename(sample_files[0])} ,right: {os.path.basename(sample_files[1])} ')\n",
    "\n",
    "df1 = dd.read_parquet(sample_files[0])\n",
    "df2 = dd.read_parquet(sample_files[1])\n",
    "\n",
    "result = df1.merge(df2, how='left', on=linked_features)\n",
    "result.to_parquet(merged_folder, engine='pyarrow', write_index=False)\n",
    "print(len(result.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b83285f-c05c-4b19-8fd0-ef80f6ebc5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import glob\n",
    "import os \n",
    "\n",
    "sample_folder = 'new_sample_one/'\n",
    "merged_folder = 'merged_sample_one/'\n",
    "\n",
    "os.makedirs(merged_folder, exist_ok=True)\n",
    "\n",
    "sample_files = glob.glob(sample_folder + \"*.parquet\")\n",
    "merged_sample_file = os.path.basename(glob.glob(merged_folder + \"*.parquet\")[0])\n",
    "\n",
    "print(f'left join, left: {merged_sample_file} ,right: {os.path.basename(sample_files[2])} ')\n",
    "\n",
    "df1 = dd.read_parquet(merged_folder+merged_sample_file)\n",
    "df2 = dd.read_parquet(sample_files[2])\n",
    "\n",
    "result = df1.merge(df2, how='left', on=linked_features)\n",
    "result.to_parquet(merged_folder, engine='pyarrow', write_index=False)\n",
    "print(len(result.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3c17a3-04ef-4675-97a1-bb6a30b1634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import glob\n",
    "import os \n",
    "\n",
    "sample_folder = 'new_sample_one/'\n",
    "merged_folder = 'merged_sample_one/'\n",
    "merged_sample_file = 'sample_one_merged.parquet'\n",
    "\n",
    "os.makedirs(merged_folder, exist_ok=True)\n",
    "\n",
    "sample_files = glob.glob(sample_folder + \"*.parquet\")\n",
    "merged_sample_file = os.path.basename(glob.glob(merged_folder + \"*.parquet\")[0])\n",
    "\n",
    "print(f'left join, left:{merged_sample_file} ,right: {os.path.basename(sample_files[3])} ')\n",
    "\n",
    "df1 = dd.read_parquet(merged_folder+merged_sample_file)\n",
    "df2 = dd.read_parquet(sample_files[3])\n",
    "\n",
    "result = df1.merge(df2, how='left', on=linked_features)\n",
    "result.to_parquet(merged_folder, engine='pyarrow', write_index=False)\n",
    "print(len(result.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c8a126-470f-4148-999c-b85a593bd635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import glob\n",
    "import os \n",
    "\n",
    "sample_folder = 'new_sample_one/'\n",
    "merged_folder = 'merged_sample_one/'\n",
    "\n",
    "os.makedirs(merged_folder, exist_ok=True)\n",
    "\n",
    "sample_files = glob.glob(sample_folder + \"*.parquet\")\n",
    "merged_sample_file = os.path.basename(glob.glob(merged_folder + \"*.parquet\")[0])\n",
    "\n",
    "print(f'left join, left:{merged_sample_file} ,right: {os.path.basename(sample_files[4])} ')\n",
    "\n",
    "\n",
    "df1 = dd.read_parquet(merged_folder + merged_sample_file).repartition(npartitions=32)\n",
    "df2 = dd.read_parquet(sample_files[4])\n",
    "\n",
    "result = df1.merge(df2, how='left', on=linked_features)\n",
    "result.to_parquet(merged_folder, engine='pyarrow', write_index=False)\n",
    "print(len(result.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b225cf16-b82d-4026-946f-6bf200ccc724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import glob\n",
    "import os \n",
    "\n",
    "sample_folder = 'new_sample_one/'\n",
    "merged_folder = 'merged_sample_one/'\n",
    "\n",
    "os.makedirs(merged_folder, exist_ok=True)\n",
    "\n",
    "sample_files = glob.glob(sample_folder + \"*.parquet\")\n",
    "merged_sample_file = os.path.basename(glob.glob(merged_folder + \"*.parquet\")[0])\n",
    "\n",
    "print(f'left join, left:{merged_sample_file} ,right: {os.path.basename(sample_files[5])} ')\n",
    "\n",
    "\n",
    "df1 = dd.read_parquet(merged_folder+merged_sample_file)\n",
    "df2 = dd.read_parquet(sample_files[5])\n",
    "\n",
    "result = df1.merge(df2, how='left', on=linked_features[:3])\n",
    "result.to_parquet(merged_folder, engine='pyarrow', write_index=False)\n",
    "print(len(result.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7324c1-001f-434d-8b3c-3c838fc695fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import glob\n",
    "import os \n",
    "\n",
    "sample_folder = 'new_sample_one/'\n",
    "merged_folder = 'merged_sample_one/'\n",
    "\n",
    "os.makedirs(merged_folder, exist_ok=True)\n",
    "\n",
    "sample_files = glob.glob(sample_folder + \"*.parquet\")\n",
    "merged_sample_file = os.path.basename(glob.glob(merged_folder + \"*.parquet\")[0])\n",
    "\n",
    "print(f'left join, left:{merged_sample_file} ,right: {os.path.basename(sample_files[6])} ')\n",
    "\n",
    "\n",
    "df1 = dd.read_parquet(merged_folder+merged_sample_file)\n",
    "df2 = dd.read_parquet(sample_files[6])\n",
    "\n",
    "result = df1.merge(df2, how='left', on=linked_features[:3])\n",
    "result.to_parquet(merged_folder, engine='pyarrow', write_index=False)\n",
    "print(len(result.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc5021a-ae48-4cb5-8a74-7ae9ca943a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import glob\n",
    "import os \n",
    "\n",
    "sample_folder = 'new_sample_one/'\n",
    "merged_folder = 'merged_sample_one/'\n",
    "\n",
    "os.makedirs(merged_folder, exist_ok=True)\n",
    "\n",
    "sample_files = glob.glob(sample_folder + \"*.parquet\")\n",
    "merged_sample_file = os.path.basename(glob.glob(merged_folder + \"*.parquet\")[0])\n",
    "\n",
    "print(f'left join, left:{merged_sample_file} ,right: {os.path.basename(sample_files[7])} ')\n",
    "\n",
    "\n",
    "df1 = dd.read_parquet(merged_folder+merged_sample_file)\n",
    "df2 = dd.read_parquet(sample_files[7])\n",
    "\n",
    "result = df1.merge(df2, how='left', on=linked_features)\n",
    "result.to_parquet(merged_folder, engine='pyarrow', write_index=False)\n",
    "print(len(result.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf69aeb-b2d6-4e5f-b91e-c70b22550899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import glob\n",
    "import os \n",
    "\n",
    "sample_folder = 'new_sample_one/'\n",
    "merged_folder = 'merged_sample_one/'\n",
    "\n",
    "os.makedirs(merged_folder, exist_ok=True)\n",
    "\n",
    "sample_files = glob.glob(sample_folder + \"*.parquet\")\n",
    "merged_sample_file = os.path.basename(glob.glob(merged_folder + \"*.parquet\")[0])\n",
    "\n",
    "print(f'left join, left:{merged_sample_file} ,right: {os.path.basename(sample_files[8])} ')\n",
    "\n",
    "\n",
    "df1 = dd.read_parquet(merged_folder+merged_sample_file)\n",
    "df2 = dd.read_parquet(sample_files[8])\n",
    "\n",
    "result = df1.merge(df2, how='left', on=linked_features[:3])\n",
    "result.to_parquet(merged_folder, engine='pyarrow', write_index=False)\n",
    "print(len(result.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed4052a-c849-4ae3-a92a-ee8257d346b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import glob\n",
    "import os \n",
    "\n",
    "sample_folder = 'new_sample_one/'\n",
    "merged_folder = 'merged_sample_one/'\n",
    "\n",
    "os.makedirs(merged_folder, exist_ok=True)\n",
    "\n",
    "sample_files = glob.glob(sample_folder + \"*.parquet\")\n",
    "merged_sample_file = os.path.basename(glob.glob(merged_folder + \"*.parquet\")[0])\n",
    "\n",
    "print(f'left join, left:{merged_sample_file} ,right: {os.path.basename(sample_files[9])} ')\n",
    "\n",
    "df1 = dd.read_parquet(merged_folder+merged_sample_file)\n",
    "df2 = dd.read_parquet(sample_files[9])\n",
    "\n",
    "result = df1.merge(df2, how='left', on=linked_features[:3])\n",
    "result.to_parquet(merged_folder, engine='pyarrow', write_index=False)\n",
    "print(len(result.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bada29c5-ecac-4075-92e0-a55e73c98b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import glob\n",
    "import os \n",
    "\n",
    "sample_folder = 'new_sample_one/'\n",
    "merged_folder = 'merged_sample_one/'\n",
    "\n",
    "os.makedirs(merged_folder, exist_ok=True)\n",
    "\n",
    "sample_files = glob.glob(sample_folder + \"*.parquet\")\n",
    "merged_sample_file = os.path.basename(glob.glob(merged_folder + \"*.parquet\")[0])\n",
    "\n",
    "print(f'left join, left:{merged_sample_file} ,right: {os.path.basename(sample_files[10])} ')\n",
    "\n",
    "\n",
    "df1 = dd.read_parquet(merged_folder+merged_sample_file)\n",
    "df2 = dd.read_parquet(sample_files[10])\n",
    "\n",
    "result = df1.merge(df2, how='left', on=linked_features)\n",
    "result.to_parquet(merged_folder, engine='pyarrow', write_index=False)\n",
    "print(len(result.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03100f7-4e6a-473d-bcc2-d65273150256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import glob\n",
    "import os \n",
    "\n",
    "sample_folder = 'new_sample_one/'\n",
    "merged_folder = 'merged_sample_one/'\n",
    "\n",
    "os.makedirs(merged_folder, exist_ok=True)\n",
    "\n",
    "sample_files = glob.glob(sample_folder + \"*.parquet\")\n",
    "merged_sample_file = os.path.basename(glob.glob(merged_folder + \"*.parquet\")[0])\n",
    "\n",
    "print(f'left join, left:{merged_sample_file} ,right: {os.path.basename(sample_files[11])} ')\n",
    "\n",
    "\n",
    "df1 = dd.read_parquet(merged_folder+merged_sample_file)\n",
    "df2 = dd.read_parquet(sample_files[11])\n",
    "\n",
    "result = df1.merge(df2, how='left', on=linked_features)\n",
    "result.to_parquet(merged_folder, engine='pyarrow', write_index=False)\n",
    "print(len(result.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92501593-e1c0-431e-b555-3d9b5b629311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import glob\n",
    "import os \n",
    "\n",
    "sample_folder = 'new_sample_one/'\n",
    "merged_folder = 'merged_sample_one/'\n",
    "\n",
    "os.makedirs(merged_folder, exist_ok=True)\n",
    "\n",
    "sample_files = glob.glob(sample_folder + \"*.parquet\")\n",
    "merged_sample_file = os.path.basename(glob.glob(merged_folder + \"*.parquet\")[0])\n",
    "\n",
    "print(f'left join, left:{merged_sample_file} ,right: {os.path.basename(sample_files[12])} ')\n",
    "\n",
    "df1 = dd.read_parquet(merged_folder+merged_sample_file)\n",
    "df2 = dd.read_parquet(sample_files[12])\n",
    "\n",
    "result = df1.merge(df2, how='left', on=linked_features)\n",
    "result.to_parquet(merged_folder, engine='pyarrow', write_index=False)\n",
    "print(len(result.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fe3448-1b7e-41de-acc7-f7558f6a493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import glob\n",
    "import os \n",
    "\n",
    "sample_folder = 'new_sample_one/'\n",
    "merged_folder = 'merged_sample_one/'\n",
    "\n",
    "os.makedirs(merged_folder, exist_ok=True)\n",
    "\n",
    "sample_files = glob.glob(sample_folder + \"*.parquet\")\n",
    "merged_sample_file = os.path.basename(glob.glob(merged_folder + \"*.parquet\")[0])\n",
    "\n",
    "print(f'left join, left:{merged_sample_file} ,right: {os.path.basename(sample_files[13])} ')\n",
    "\n",
    "\n",
    "df1 = dd.read_parquet(merged_folder+merged_sample_file)\n",
    "df2 = dd.read_parquet(sample_files[13])\n",
    "\n",
    "result = df1.merge(df2, how='left', on=linked_features)\n",
    "result.to_parquet(merged_folder, engine='pyarrow', write_index=False)\n",
    "print(len(result.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eb9367-0311-4ce3-b806-5a6b8732299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import glob\n",
    "import os \n",
    "\n",
    "sample_folder = 'new_sample_one/'\n",
    "merged_folder = 'merged_sample_one/'\n",
    "\n",
    "os.makedirs(merged_folder, exist_ok=True)\n",
    "\n",
    "sample_files = glob.glob(sample_folder + \"*.parquet\")\n",
    "merged_sample_file = os.path.basename(glob.glob(merged_folder + \"*.parquet\")[0])\n",
    "\n",
    "print(f'left join, left:{merged_sample_file} ,right: {os.path.basename(sample_files[14])} ')\n",
    "\n",
    "\n",
    "df1 = dd.read_parquet(merged_folder+merged_sample_file)\n",
    "df2 = dd.read_parquet(sample_files[14])\n",
    "\n",
    "result = df1.merge(df2, how='left', on=linked_features)\n",
    "result.to_parquet(merged_folder, engine='pyarrow', write_index=False)\n",
    "print(len(result.columns))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
